rm(list=ls())

#Does feature selection by selecting the most important eigenvectors, 
#analysing the mean contributions to each eigenvector by each feature, and sorting


#Input: contains one colum for each feature
dataset<-"SampleDataSet.csv"
output_dataset<-"SampleDataSet_reduced.csv"

#####PARAMETERS#####
#generates simulated data and demonstrates how it works
demo<-F
#scale the data: to use only if the variable ranges are too different
scale_data<-T
#select the PCs explaining up to 95% of the variance
eigenvector_threshold<-0.95
#select the variables contributing to 80% of the PCs
variables_threshold<-0.8
#plot: if T the first two variables and the PC lines will be plotted
plot<-F

if (demo){
  cat("Simulating data...\n")
  scale_data<-F
  nr.points<-10000
  small<-runif(250,min=0,max=1) #rnorm(nr.points,mean = 1, sd = 0.01)
  large<-runif(250,min=0,max=250)#rnorm(nr.points,mean = 10, sd = 10)
  #small<- (large) + 10*rnorm(nr.points)#runif(nr.points)
  df.sim<-data.frame(small=small,large=large)
  
  l1<-runif(250,min=0,max=1) 
  l2<-runif(250,min=0,max=10) 
  l3<-runif(250,min=0,max=100)
  l4<-runif(250,min=0,max=250)
  l5<-runif(250,min=0,max=500)
  l6<-runif(250,min=0,max=1000)
  l7<-runif(250,min=0,max=2000)
  l8<-runif(250,min=0,max=2500)
  l9<-runif(250,min=0,max=3000)
  l10<-runif(250,min=0,max=4000)
  #df.sim<-data.frame(l1=l1,l2=l2,l3=l3,l4=l4)
  df.sim<-data.frame(l1=l1,l2=l2,l3=l3,l4=l4,l5=l5,l6=l6,l7=l7,l8=l8,l9=l9,l10=l10)
  #df.sim<-data.frame(l2=l2,l3=l3,l4=l4)
  #df.sim<-data.frame(l1=l1,l2=l2)
  df<-df.sim
}else{
  df<-read.csv(dataset, header =T, sep=",")
}


#### 1) center and scale the data
if (scale_data){
  cat("Scaling data...\n")
  df.means<-as.vector(t(colMeans(df)))
  dfm<-as.matrix(df)
  df.sub<-sweep(dfm, 2, df.means,FUN = "-")
  df.sd<-apply(df,2,sd)
  df.scaled<-sweep(df.sub, 2, df.sd, FUN = "/")
}else{
  df.scaled<-as.matrix(df)
}

cat("Computing PCA...\n")
#### 2) compute the correlation matrix
#old code to do eigenvalue extraction by hand
#cor.matrix <- cor(df.scaled, use="na.or.complete")
#eigenv <- eigen(cor.matrix)
#eigenvectors<-eigenv$vectors
#eigenvalues<-eigenv$values

pc <- prcomp(df.scaled,
             center = F,
             scale. = F)

#### 3) get the eigenvectors and values
eigenvectors<-as.matrix(pc$rotation)
eigenvalues<-pc$sdev
importance<-as.vector(summary(pc)$importance[2,])

cat("Eigenvalues:",eigenvalues,"\n")
cat("Eigenvectors (one for each column):\n")
print(eigenvectors)

#### 4) filter the eigenvectors to those capturing the highest variance
#normalise the eigenvalues
eigenperc<-importance #eigenvalues/sum(eigenvalues)
cat("Eigenvalues percentages:\n")
print(eigenperc*100)

cumulative.contrib<-0
eigenvalidx<-1
for (i in 1:length(eigenperc)){
  
  cumulative.contrib = cumulative.contrib+eigenperc[i]
  if (cumulative.contrib>=eigenvector_threshold){
    eigenvalidx=i
    cat("Stopping at eigenvalue",eigenvalidx," containing cumulative contribution = ",(cumulative.contrib),">=",eigenvector_threshold,"\n")
    break
  }
}
#select the most important eigenvectors
reduced.eigenvectors<-eigenvectors[,1:eigenvalidx]
reduced.eigenperc<-eigenperc[1:eigenvalidx]
if (is.null(dim(reduced.eigenvectors))){
  reduced.eigenvectors<-data.frame(v1=reduced.eigenvectors)
}else{
  reduced.eigenvectors<-data.frame(reduced.eigenvectors)
}
cat("Eigenvectors filtered:\n")
print(reduced.eigenvectors)
if (plot){
  plot(df.scaled,col='red')
  for (i in 1:dim(reduced.eigenvectors)[2]){
    eig<-reduced.eigenvectors[,i]
    abline(a=0, b=eig[2]/eig[1])
  }
}

#### 5) Evaluate the error generated by transforming the data from the eigenvector space to the original with one filtered eigenvectors
# The projected complete dataset
df.proj <- df.scaled %*% as.matrix(eigenvectors)
#project the eigenvalues
df.proj.reduced <- df.scaled %*% as.matrix(reduced.eigenvectors)
#the reprojected bacwards matrix should almost be the same
df.proj.reduced.reproj <- df.proj.reduced %*% t(reduced.eigenvectors)
error.committed<-mean(apply(abs(df.scaled-df.proj.reduced.reproj),2,mean))
cat("Reprojection error with the reduced space:",error.committed,"\n")

#### 6) Calculate the loadings of the filtered eigenvectors
#take the eigenvectors' original coordinates in the parameter space - one row for each eigenvector, one column for each feature
reduced.eigenvectors.features<-t(reduced.eigenvectors)
reduced.eigenvectors.features<-as.data.frame(reduced.eigenvectors.features)
names(reduced.eigenvectors.features)<-names(df)
#calculate the absolute length of each component
reduced.eigenvectors.features.abs<-abs(reduced.eigenvectors.features)
reduced.eigenvectors.features.abs.weig<-sapply(1:dim(reduced.eigenvectors.features)[2], 
  function(i){
    column<-reduced.eigenvectors.features.abs[,i]
    column<-column*reduced.eigenperc
    return(column)
},simplify = T)

reduced.eigenvectors.features.abs.weig<-as.data.frame(matrix(reduced.eigenvectors.features.abs.weig,nrow = dim(reduced.eigenvectors.features)[1],ncol=dim(reduced.eigenvectors.features)[2]))
names(reduced.eigenvectors.features.abs.weig)<-names(df)

#take the sum of the absolute lengths on each component
reduced.eigenvectors.features.abs.sum<-apply(reduced.eigenvectors.features.abs.weig,2,"sum")
#normalise the mean w.r.t. the total
reduced.eigenvectors.features.abs.sum.norm<-reduced.eigenvectors.features.abs.sum/sum(reduced.eigenvectors.features.abs.sum)
#sort the mean contribution of each variable to each eigenvector
reduced.eigenvectors.features.df <- data.frame(c = reduced.eigenvectors.features.abs.sum.norm)
reduced.eigenvectors.features.df.ordered<-reduced.eigenvectors.features.df[order(reduced.eigenvectors.features.df$c, decreasing=T),, drop=FALSE]
cat("Sorted features' contributions\n")
print(reduced.eigenvectors.features.df.ordered)

#### 7) Filter lower-contribution features
cumulative.contrib.f<-0
featurevalidx<-1
for (i in 1:length(reduced.eigenvectors.features.df.ordered$c)){
  
  cumulative.contrib.f = cumulative.contrib.f+reduced.eigenvectors.features.df.ordered$c[i]
  if (cumulative.contrib.f>variables_threshold){
    featurevalidx=i
    cat("Stopping at variable",row.names(reduced.eigenvectors.features.df.ordered)[i],"#",i,"over",length(reduced.eigenvectors.features.df.ordered$c)," containing cumulative contribution = ",(cumulative.contrib.f),">",variables_threshold,"\n")
    break
  }
  cat("Including variable",row.names(reduced.eigenvectors.features.df.ordered)[i],"\n")
}
#filter features
reduced.eigenvectors.features.df.filtered<-reduced.eigenvectors.features.df.ordered[1:featurevalidx,]

#### 8) Report the highest-contribution features
f.names.selected<-row.names(reduced.eigenvectors.features.df.ordered)[1:featurevalidx]
#report the dataset after eliminating all lower-importance features
filtered.df<-df[f.names.selected]
cat("\n####Selected variables:",f.names.selected,"\n")


write.csv(filtered.df,file=output_dataset,row.names = F)
cat("done\n")
